[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Challenge 1: Tidyverse",
    "section": "",
    "text": "# Loading libraries ----\nlibrary(tidyverse)\n\n#> Warning: package 'tidyverse' was built under R version 4.2.3\n\n\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n\n\n#> Warning: package 'tibble' was built under R version 4.2.3\n\n\n#> Warning: package 'tidyr' was built under R version 4.2.3\n\n\n#> Warning: package 'readr' was built under R version 4.2.3\n\n\n#> Warning: package 'purrr' was built under R version 4.2.3\n\n\n#> Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#> Warning: package 'stringr' was built under R version 4.2.3\n\n\n#> Warning: package 'forcats' was built under R version 4.2.3\n\n\n#> Warning: package 'lubridate' was built under R version 4.2.3\n\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\n#> Warning: package 'readxl' was built under R version 4.2.3\n\nlibrary(lubridate)\nlibrary(\"writexl\")\n\n#> Warning: package 'writexl' was built under R version 4.2.3\n\n# Importing Files ----\nbikes_tbl      <- read_excel(path = \"01_tidyverse_files/Data_bikes/01_bike_sales/01_raw_data/bikes.xlsx\")\norderlines_tbl <- read_excel(\"01_tidyverse_files/Data_bikes/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#> New names:\n#> • `` -> `...1`\n\nbikeshops_tbl  <- read_excel(\"01_tidyverse_files/Data_bikes/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n\n# Joining/connecting Data ----\nbike_orderlines_joined_tbl <- orderlines_tbl %>% \n  left_join(bikes_tbl, by =c(\"product.id\"=\"bike.id\")) %>%\n  left_join(bikeshops_tbl, by =c(\"customer.id\"=\"bikeshop.id\"))\n\n# Data Wrangling ----\n\nbike_state_wrangled_tbl <- bike_orderlines_joined_tbl%>%\n  separate(col=location,\n           into= c(\"city\",\"state\"),\n           sep= \",\")%>%\n  mutate(total.price= price * quantity)%>%\n  select(-...1, -gender)%>%\n  select(order.id,city,state,order.date, total.price, contains(\"model\"),\n         contains(\"category\"), price, quantity, everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n  \n\n# Business Analysis ----\n# Sales by Location/State ----\n\n# Data Manipulation\n\nstate_sales <- bike_state_wrangled_tbl%>%\n  select(state,total_price)%>%\n  group_by(state)%>%\n  summarize(sales=sum(total_price))%>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n# Data visualization\nstate_sales %>%\n  ggplot(aes(x = state, y = sales)) +\n  geom_col(fill = \"#d6902d\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text), vjust = -0.5, angle = 180) + # Adding labels to the bars vertically\n  geom_smooth(method = \"lm\", se = FALSE) + # trendline\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  + \n  # Formatting plot\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by States\",\n    x = \"States\",\n    y = \"Revenue\"\n  )\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe state “North Rhine-Westphalia” has the highest revenue."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Tidyverse",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Challenge 2: Data Acquisition",
    "section": "",
    "text": "For this part of the challenge, I am using a Translator API from the translator engine Deepl. The user can type a text and in our case it will be translated to any supported language. In the following example, the target language is german.\nYou can change the parameter “target_lang” in the function translate2 to change the target language to another one. Also, in the parameter “text” you can change the written text below to translate a different text.\nCode below\n\nlibrary(tidyverse)\ninstall.packages(\"devtools\", repos = \"http://cran.rstudio.com/\")\n\n#> Installing package into 'C:/Users/islam/AppData/Local/R/win-library/4.2'\n#> (as 'lib' is unspecified)\n\n\n#> package 'devtools' successfully unpacked and MD5 sums checked\n#> \n#> The downloaded binary packages are in\n#>  C:\\Users\\islam\\AppData\\Local\\Temp\\RtmpKsRVmV\\downloaded_packages\n\ndevtools::install_github(\"zumbov2/deeplr\")\n\n#> WARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 4.2.0 was found. (Only the following incompatible version(s) of Rtools were found: 4.3.5550)\n#> \n#> Please download and install Rtools 4.2 from https://cran.r-project.org/bin/windows/Rtools/ or https://www.r-project.org/nosvn/winutf8/ucrt3/.\n\n\n#> Skipping install of 'deeplr' from a github remote, the SHA1 (b9206467) has not changed since last install.\n#>   Use `force = TRUE` to force installation\n\nmy_auth_key = \"05bc2a53-360f-1d6a-540f-2b880ad44d62:fx\"\ntext_to_be_translated = \"La seule facon de savoir ce qui se passe est de perturber le systeme.\"\n\ntranslated_text <- deeplr::translate2(\n  text = text_to_be_translated,\n  target_lang = \"EN\",\n  auth_key = my_auth_key\n)\nknitr::kable(text_to_be_translated, caption = 'text to be translated')\n\n\ntext to be translated\n\nx\n\n\nLa seule facon de savoir ce qui se passe est de perturber le systeme.\n\n\n\nknitr::kable(translated_text, caption = 'translated text')\n\n\ntranslated text\n\nx\n\n\nThe only way to find out what is going on is to disrupt the system."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Challenge 3: data wrangling",
    "section": "",
    "text": "What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.List the 10 US companies with the most assigned/granted patents.\n\nlibrary(vroom)\n\n#> Warning: package 'vroom' was built under R version 4.2.3\n\nlibrary(tictoc)\n\n#> Warning: package 'tictoc' was built under R version 4.2.3\n\nlibrary(tidyverse)\n\n#> Warning: package 'tidyverse' was built under R version 4.2.3\n\n\n#> Warning: package 'ggplot2' was built under R version 4.2.3\n\n\n#> Warning: package 'tibble' was built under R version 4.2.3\n\n\n#> Warning: package 'tidyr' was built under R version 4.2.3\n\n\n#> Warning: package 'readr' was built under R version 4.2.3\n\n\n#> Warning: package 'purrr' was built under R version 4.2.3\n\n\n#> Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#> Warning: package 'stringr' was built under R version 4.2.3\n\n\n#> Warning: package 'forcats' was built under R version 4.2.3\n\n\n#> Warning: package 'lubridate' was built under R version 4.2.3\n\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ readr::col_character()   masks vroom::col_character()\n#> ✖ readr::col_date()        masks vroom::col_date()\n#> ✖ readr::col_datetime()    masks vroom::col_datetime()\n#> ✖ readr::col_double()      masks vroom::col_double()\n#> ✖ readr::col_factor()      masks vroom::col_factor()\n#> ✖ readr::col_guess()       masks vroom::col_guess()\n#> ✖ readr::col_integer()     masks vroom::col_integer()\n#> ✖ readr::col_logical()     masks vroom::col_logical()\n#> ✖ readr::col_number()      masks vroom::col_number()\n#> ✖ readr::col_skip()        masks vroom::col_skip()\n#> ✖ readr::col_time()        masks vroom::col_time()\n#> ✖ readr::cols()            masks vroom::cols()\n#> ✖ readr::date_names_lang() masks vroom::date_names_lang()\n#> ✖ readr::default_locale()  masks vroom::default_locale()\n#> ✖ dplyr::filter()          masks stats::filter()\n#> ✖ readr::fwf_cols()        masks vroom::fwf_cols()\n#> ✖ readr::fwf_empty()       masks vroom::fwf_empty()\n#> ✖ readr::fwf_positions()   masks vroom::fwf_positions()\n#> ✖ readr::fwf_widths()      masks vroom::fwf_widths()\n#> ✖ dplyr::lag()             masks stats::lag()\n#> ✖ readr::locale()          masks vroom::locale()\n#> ✖ readr::output_column()   masks vroom::output_column()\n#> ✖ readr::problems()        masks vroom::problems()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(data.table)\n\n#> \n#> Attaching package: 'data.table'\n#> \n#> The following objects are masked from 'package:lubridate':\n#> \n#>     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#>     yday, year\n#> \n#> The following objects are masked from 'package:dplyr':\n#> \n#>     between, first, last\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     transpose\n#> \n#> The following object is masked from 'package:tictoc':\n#> \n#>     shift\n\ncol_types <- list(\n  id = col_character(),\n  type = col_character(),\n  number = col_character(),\n  country = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  abstract = col_character(),\n  title = col_character(),\n  kind = col_character(),\n  num_claims = col_double(),\n  filename = col_character(),\n  withdrawn = col_double()\n)\npatent_tbl <- vroom(\n  file       = \"03_data_wrangling_files/Patent_data/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: type, number,\n#> country, abstract, title, kind, filename, withdrawn\n\nuspc_tbl <- vroom(\n  file       = \"03_data_wrangling_files/Patent_data/uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> number, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\npatent_assignee_tbl <- vroom(\n  file       = \"03_data_wrangling_files/Patent_data/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> number, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nassignee_tbl <- vroom(\n  file       = \"03_data_wrangling_files/Patent_data/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: number,\n#> country, date, abstract, title, kind, num_claims, filename, withdrawn\n\n#---------------------Question 1------------------------\nclass(assignee_tbl)\n\n#> [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\n\nsetDT(assignee_tbl)\nclass(patent_assignee_tbl)\n\n#> [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\n\nsetDT(patent_assignee_tbl)\nclass(patent_tbl)\n\n#> [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\n\nsetDT(patent_tbl)\ntic()\nQ1_patent_data <- merge(x = patent_assignee_tbl, y = assignee_tbl, \n                       by.x=\"assignee_id\", by.y =\"id\",\n                       all.x = TRUE, \n                       all.y = FALSE)\ntoc()\n\n#> 0.1 sec elapsed\n\nsetkey(Q1_patent_data, \"assignee_id\")\nkey(Q1_patent_data)\n\n#> [1] \"assignee_id\"\n\nQ1_patent_data %>% dim()\n\n#> [1] 315910      4\n\nkeep_cols <- c(\"assignee_id\",\"patent_id\",\"organization\")\nQ1_patent_data <- Q1_patent_data[, ..keep_cols]\nQ1_patent_data %>% dim()\n\n#> [1] 315910      3\n\nQ1_patent_data %>% glimpse()\n\n#> Rows: 315,910\n#> Columns: 3\n#> $ assignee_id  <chr> \"org_004j997jM9yEdS7z4ReD\", \"org_004j997jM9yEdS7z4ReD\", \"…\n#> $ patent_id    <chr> \"8728438\", \"8921361\", \"8857791\", \"8845559\", \"8815936\", \"8…\n#> $ organization <chr> \"University of Basel\", \"University of Basel\", \"Zetkama Sp…\n\n#Count_Q1 contains the data of the companies/organisations and the number of patents they hold in descending order\ntic()\nCount_Q1<- Q1_patent_data %>%\n  filter(!is.na(organization)) %>%\n  count(organization)%>% arrange(desc(n))\ntoc()\n\n#> 0.44 sec elapsed\n\n#Print the top 10 companies in a descending order\nhead(Count_Q1,10)\n\n\n\n  \n\n\n\nIBMC holds 7547 patents. This is the highest number of patents in this year."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Challenge 4: data visualization",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(tidyr)\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311581 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nshow_col_types = FALSE\n\ncovid_data_tbl <- covid_data_tbl[order(as.Date(covid_data_tbl$date, format=\"%d/%m/%Y\")),]\n\n\ncovid_data_tbl <- covid_data_tbl %>%\n  mutate_if(is.numeric,~replace_na(.,0))\n\n\ncovid_data_tbl2 <- covid_data_tbl %>%\n  filter(location %in% c('Spain', 'United Kingdom', 'France', 'Germany','United States')) %>%\n  select(date, location, new_cases) %>%\n  group_by(location) %>%\n  mutate(cumulativeCases = cumsum(new_cases))  %>%\n  select(date, location, cumulativeCases) %>%\n  rename(countries = location)\n\n\n# Custom function to format labels in million abbreviation\ncustom_y_labels <- function(y) {\n  y_million <- y / 1e+06\n  paste0(y_million, \" Mio\")\n}\n \n\n# Plot \nticks = c(\"Dec\",\"Jan\", 'Feb','March', 'April', 'May', 'June','July',\n          'Aug','Sept','Oct','Nov','Dec')\n\ny_ticks = seq(0,max(covid_data_tbl2$cumulativeCases, na.rm = TRUE, finite = TRUE),50000000)\ncovid_data_tbl2 %>%\n  ggplot(aes(x = as.POSIXct(date, format = \"%B '%y\"), y = cumulativeCases)) +\n  geom_line(aes(color = countries), size = 1) +\n  labs(x = 'Year 2020', y='Cumulative Cases', fill = 'Countries') +\n  scale_x_datetime(date_breaks = 'month', labels = label_date_short()) +\n  scale_y_continuous(breaks=c(y_ticks))\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead."
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#analyze-the-sales-by-location-and-year.",
    "href": "content/01_journal/01_tidyverse.html#analyze-the-sales-by-location-and-year.",
    "title": "Challenge 1: Tidyverse",
    "section": "\n2.1 Analyze the sales by location and year.",
    "text": "2.1 Analyze the sales by location and year.\n\n# Sales by Location and Year----\n\n# Data Manipulation\nsales_by_location_year <- bike_state_wrangled_tbl %>%\n  \n  # Enriching columns by adding a year column\n  select(order_date, total_price,state) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Group by and summarize year and state\n  group_by(year,state) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Format $ Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\n# Visualization\nsales_by_location_year %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by year and State\",\n    fill = \"States\" # Changes the legend name\n  )"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "href": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "title": "Challenge 3: data wrangling",
    "section": "\n2.1 Recent patent activity",
    "text": "2.1 Recent patent activity\nWhat US company had the most patents granted in August 2014? List the top 10 companies with the most new granted patents for August 2014.\n\nclass(patent_tbl)\n\n#> [1] \"data.table\" \"data.frame\"\n\nsetDT(patent_tbl)\n#Q2_patent_all has patent,patent data,assigned data merged\ntic()\nQ2_patent_all <- merge(x = patent_tbl, y = Q1_patent_data, \n                        by.x=\"id\", by.y =\"patent_id\",\n                        all.x = TRUE, \n                        all.y = FALSE)\ntoc()\n\n#> 0.38 sec elapsed\n\n#Selecting a timeframe (Aug 1 2014 to Aug 31 2014) and building a new data frame Q2_Aug_patents\nQ2_Aug_patents<- with(Q2_patent_all, Q2_patent_all[(date >= \"2014-08-01\" & date <= \"2014-08-31\") ])\n#Count_Aug has the data of all the organisations that got a patent in Aug 2014 in desc order \n#with number of patents\ntic()\nCount_Aug<- Q2_Aug_patents %>%\n  filter(!is.na(organization)) %>%\n  count(organization)%>% arrange(desc(n))\ntoc()\n\n#> 0.05 sec elapsed\n\n#Company with most patents, Aug 2014\nhead(Count_Aug,1)\n\n\n\n  \n\n\n#Top 10 companies with new patents, Aug 2014\nhead(Count_Aug,10)\n\n\n\n  \n\n\n\nThe above list shows the top 10 companies with the most new granted patents for August 2014."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "href": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "title": "Challenge 3: data wrangling",
    "section": "\n3.1 Innovation in Tech",
    "text": "3.1 Innovation in Tech\nWhat is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?\n\ntic()\nQ3_patent_all <- merge(x = uspc_tbl, y = Q1_patent_data, \n                       by.x=\"patent_id\", by.y =\"patent_id\",\n                       all.x = TRUE, \n                       all.y = FALSE)\ntoc()\n\n#> 3.9 sec elapsed\n\n#Most innovative class can be calculated by summing the total number of patents for each class\ntic()\nmostinnovative_class_Q3<- Q3_patent_all %>%\n  filter(!is.na(mainclass_id)) %>%\n  count(mainclass_id)%>% arrange(desc(n))\ntoc()\n\n#> 0.3 sec elapsed\n\n#creating a dataframe of top10 companies only to investigate the top 5 USPTO\nQ3_top10 <- Q3_patent_all[Q3_patent_all$organization %in% c('International Business Machines Corporation','Samsung Electronics Co., Ltd.','Canon Kabushiki Kaisha','Sony Corporation','Microsoft Corporation','Google Inc.','Kabushiki Kaisha Toshiba','QUALCOMM Incorporated','LG Electronics Inc.','Panasonic Corporation'),]\n#adding a new column with has Company name & Class together titled \"Company_Class\"\nQ3_top10$Company_Class <- paste(Q3_top10$organization, Q3_top10$mainclass_id)\n#Counting the Company_class and arranging in desc order\ntic()\nQ3_top10_CC<- Q3_top10 %>%\n  count(Company_Class)%>% arrange(desc(n))\ntoc()\n\n#> 0.01 sec elapsed\n\n#displaying the most innovative class and its corresponding number of patents of that class\nhead(mostinnovative_class_Q3,1)\n\n\n\n  \n\n\n#Shows the top 5 USPTO Classes from the top 10 companies granted patents\nhead(Q3_top10_CC,5)\n\n\n\n  \n\n\n\nThe above table shows the top 5 USPTO tech main classes, from the top 10 companies in a descending order"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#visualize-the-distribution-of-the-mortality-rate-deaths-population.",
    "href": "content/01_journal/04_data_visualization.html#visualize-the-distribution-of-the-mortality-rate-deaths-population.",
    "title": "Challenge 4: data visualization",
    "section": "\n2.1 Visualize the distribution of the mortality rate (deaths / population).",
    "text": "2.1 Visualize the distribution of the mortality rate (deaths / population).\n\nlibrary(maps)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\ntheme_set(\n  theme_dark()\n)\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311581 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nworld <- map_data('world') %>%\n  rename(countries = region) %>%\n  dplyr::select(countries,long,lat,group) \n  \ncovid_data_tbl <- covid_data_tbl %>%\n  mutate(across(location, str_replace_all, \"_\", \" \")) %>%\n  mutate(location = case_when(\n    \n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n    \n  ))\n\n#> Warning: There was 1 warning in `mutate()`.\n#> ℹ In argument: `across(location, str_replace_all, \"_\", \" \")`.\n#> Caused by warning:\n#> ! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\n#> Supply arguments directly to `.fns` through an anonymous function instead.\n#> \n#>   # Previously\n#>   across(a:b, mean, na.rm = TRUE)\n#> \n#>   # Now\n#>   across(a:b, \\(x) mean(x, na.rm = TRUE))\n\npopulation <- covid_data_tbl %>%\n  group_by(location) %>%\n  dplyr::select(location, population) %>%\n  unique() %>%\n  rename(countries = location)\n\ncovid_data_tbl <- covid_data_tbl %>%\n  mutate_if(is.numeric,~replace_na(.,0))\n\nmortality_rate_tbl <- covid_data_tbl %>%\n  group_by(location) %>%\n  summarise( \n    total_deaths = sum(new_deaths)\n    ) %>%\n  rename(countries = location)\n\nuseful_map <- left_join(population,mortality_rate_tbl, by = \"countries\")\nfinal_tbl <- left_join(world, useful_map, by = 'countries') %>%\n  mutate(mort_rate = total_deaths / population)\n#plotting the values\nggplot(final_tbl, aes(long, lat, group = group))+\n  geom_polygon(aes(fill = mort_rate), color = \"white\")+\n  scale_fill_gradient(low = 'pink', high = 'red', na.value = 'white')"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#scrape-one-of-the-competitor-websites-of-canyon",
    "href": "content/01_journal/02_data_acquisition.html#scrape-one-of-the-competitor-websites-of-canyon",
    "title": "Challenge 2: Data Acquisition",
    "section": "\n2.1 Scrape one of the competitor websites of canyon",
    "text": "2.1 Scrape one of the competitor websites of canyon\n\nlibrary(RSQLite)\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(glue)\nlibrary(jsonlite)\nlibrary(rvest)\nlibrary(stringi)\nlibrary(xopen)\nlibrary(dplyr)\nbase_url <- 'https://www.rosebikes.com/bikes'\n# 1. Function to get bike family URLs.\nget_bike_family_urls <- function(base_url) {\n  \n  bike_family_urls <- read_html(base_url) %>%\n    html_nodes(css = \".catalog-categories-item > a\") %>%\n    html_attr('href') %>%\n    \n    # Convert vector to tibble\n    \n    enframe(name = \"position\", value = \"subdirectory\") %>%\n    # Add the domain because we will get only the subdirectories\n    mutate(\n      url = glue('https://www.rosebikes.com{subdirectory}')\n    ) \n  \n\n  \n}\n# 2. Function to get bike family URLs.\nget_model_urls <- function(url) {\n  \n  bike_type_url <- read_html(url) %>%\n    html_nodes(css = \".catalog-category-bikes__content > a\") %>%\n    html_attr('href') %>%\n    enframe(name = \"position\", value = \"url\") %>%\n    mutate(url = glue('https://www.rosebikes.com{url}')) \n}\n# 3. Function to get the names of each bike \nget_bike_names <- function(url) {\n  \n  bike_model_name_tbl <- read_html(url) %>%\n    html_nodes(css = \".catalog-category-model__title\") %>%\n    html_text() %>%\n    # Convert vector to tibble\n    as_tibble()\n  \n  \n}\n# 4. Function to get the prices of each bike \nget_bike_prices <- function(url) {\n  \n  bike_model_price_tbl <- read_html(url) %>%\n    html_nodes(css = \".product-tile-price__current-value\") %>%\n    html_text() %>%\n    # Convert vector to tibble\n    as_tibble()\n  \n}\n#### APPLYING ABOVE FUNCTIONS\nbike_family_url_tbl <- get_bike_family_urls(base_url)\nbike_family_url_tbl <- bike_family_url_tbl %>%\n  slice(2:5) # Pick 3 categories\n# Create a table with bike model URLS\nbike_model_url_tbl <- tibble()\nfor (i in seq_along(bike_family_url_tbl$url)) {\n  \n  web <- toString(bike_family_url_tbl$url[i])\n  bike_model_url_tbl <- bind_rows(bike_model_url_tbl, get_model_urls(web))\n  \n}\n# Create a table with bike model names\nbike_model_names_tbl <- tibble()\nfor (i in seq_along(bike_model_url_tbl$url)) {\n  \n  web <- toString(bike_model_url_tbl$url[i])\n  bike_model_names_tbl <- bind_rows(bike_model_names_tbl, get_bike_names(web))\n  \n}\n# Rename cols\nnames(bike_model_names_tbl)[1] <- \"Bike Model\"\n# Create a table with bike prices\nbike_model_prices_tbl <- tibble()\nfor (i in seq_along(bike_model_url_tbl$url)) {\n  web <- toString(bike_model_url_tbl$url[i])\n  bike_model_prices_tbl <- bind_rows(bike_model_prices_tbl, get_bike_prices(web))\n}\n# Rename columns\nnames(bike_model_prices_tbl)[1] <- \"Bike Price\"\n# Visualize scraped data into a table \ntable_of_prices <- bind_cols(bike_model_names_tbl,bike_model_prices_tbl)\nknitr::kable(table_of_prices[1:10, ], caption = 'Rosebike.com bicycle model \"Road\" including prices')\n\n\nRosebike.com bicycle model “Road” including prices\n\nBike Model\nBike Price\n\n\n\nXLITE 04 105\n€2,999.00\n\n\nXLITE 04 Ultegra\n€3,299.00\n\n\nXLITE 04 105 Di2\n€3,599.00\n\n\nXLITE 04 Ultegra Di2\n€4,599.00\n\n\nXLITE 04 Force eTap AXS\n€4,599.00\n\n\nXLITE 04 Force AXS\n€4,999.00\n\n\nXLITE 06 Ultegra\n€3,999.00\n\n\nXLITE 06 Ultegra Di2\n€5,999.00\n\n\nXLITE 06 Force eTap AXS\n€5,999.00\n\n\nXLITE 06 Force AXS\n€6,499.00"
  }
]